\section{Prior work}
\label{sec:prior}

\emph{\textbf{Phase retrieval:}} Approaches to solve phase retrieval problem can be broadly classified into two categories: convex and non-convex. 
Convex approach usually consist of solving a constraint optimization problem after linearizing the problem. PhaseLift algorithm \cite{candes2013phaselift} and its variations \cite{gross2017improved}, \cite{candes2015phasediff} come under this category. Typical non-convex approaches involve finding a good initialization followed by iterative minimization, \textit{e.g.} Approaches based on Amplitude flow \cite{wang2016sparse,wang2016solving} and Wirtinger flow \cite{candes2015phase, zhang2016reshaped,  chen2015solving, cai2016optimal}.

In recent works, phase retrieval problem for the cases where underlying signal is sparse is of growing interest. Some of the convex approaches for sparse phase retrieval includes \cite{ohlsson2012cprl, li2013sparse,bahmani2015efficient,jaganathan2012recovery}. Similarly, non-convex approaches for sparse phase retrieval includes \cite{netrapalli2013phase, cai2016optimal, wang2016sparse}. Our approach in this paper towards solving the modulo recovery problem is mainly inspired from the non-convex sparse phase retrieval framework advocated in \cite{Jagatap2017}. 

\emph{\textbf{Modulo recovery:}} The modulo recovery problem is also known in the literature
as phase unwrapping. The algorithm proposed in \cite{bioucas2007phase} is specialized to images, and employs graph cuts for phase unwrapping from a single modulo measurement per pixel. However, the inherent assumption that the input image has very few sharp discontinuities makes it unsuitable for practical situations with textured images. Our main motivation for this paper is the work of \cite{ICCP15_Zhao} on HDR imaging using a modulo camera sensor. It proposes multi-shot UHDR algorithm for image reconstruction using multiple measurements. The more robust version of it is further proposed in \cite{Lang2017}. However, both these methods depend on carefully decided camera exposures and don't include sparsity in their models. In our previous work \cite{Shah}, we proposed an algorithm based on \cite{ICCP15_Zhao, soltani2017stable} for signal recovery from quantized modulo measurements, which can also be adapted for sparse measurements. 

Given the modulo samples of a bandlimited function, \cite{Bhandari} provides a stable algorithm for perfect recovery of the signal and also proves sufficiency conditions that guarantees the perfect recovery. \cite{Cucuringu2017} formulates and solves an QCQP problem with non-convex constraints for recovering the correct samples of the unknown function from its modulo 1 ($R =1$) samples. However, both these methods relay on the smoothness of the bandlimited function as a prior structure on the signal, and can't be used in our setup.

\begin{table*}[t]
	\begin{tabular}{p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}}
		\cline{1-6}
		& Bhandari et al.~\cite{Bhandari}  & Cucuringu and Tyagi et al.~\cite{Cucuringu2018} &Zhao et al. single shot UHDR \cite{ICCP15_Zhao}    & Zhao et al. - multishot UHDR~\cite{ICCP15_Zhao}  & MoRAM (our approach) \\ \cline{1-6}
		Sampling attribute along Time/Space dimension & Nyquist-Shannon (i.e. smoothness, uniform grid) & Nyquist-Shannon (i.e. smoothness, uniform grid) &Nyquist-Shannon (i.e. smoothness, uniform grid)& Nyquist-Shannon (i.e. smoothness, uniform grid) & Compressive Sampling (sub-Nyquist) \\ \cline{1-6}
		Sampling attribute along Amplitude dimension   & Modulo sampling        & Modulo sampling  & Modulo sampling   & Modulo sampling   & Modulo sampling   \\ \cline{1-6}
		Basis   & Canonical (time/space)     & Canonical (time/space)   & Canonical (time/space) & Canonical (time/space)  & Sparse (Fourier, wavelet etc.)  \\ \cline{1-6}
		Provides sample complexity bounds?  & Yes  & No  & No   & No & Yes \\ \cline{1-6}
		Assumption on structure of signal  & Bandlimited, i.e. smoothness assumption   & Bandlimited, i.e. smoothness assumption & smoothness assumption in spatial domain   & No assumptions      & Sparsity     \\ \cline{1-6}
		Sampling type with reference to Nyquist sampling rate  & oversampled   & --Unclear--   & indentically sampled  & oversampled   & undersampled  \\ \cline{1-6}
		Sample complexity  & $\pi n$    & --Unclear--     & n   & Kn   & O(slog(n) + Ks) \\ \cline{1-6}
		Leverages Sparsity/ CS?  & No & No  & No  & No    & Yes \\ \cline{1-6}
		Bound on Dynamic range   & Theoratically unbounded   & Theoratically unbounded  & Theoratically unbounded   & Theoratically unbounded   & Limited to $2R$  \\ \cline{1-6}                 
	\end{tabular}
\end{table*}

\textcolor{red}{ About comparision between Bhandari et al. and Our approach:: \\
According to Nyqist-Shannon criterion, a bandlimited signal can be uniquely represented through its samples collected at a sampling frequency twice its bandwidth. Many variations of this theorems are studied, but in most cases the variation arise from the diversity along time dimension, i.e., sparsity vs smoothness or uniform vs non-uniform grid. In Bhandari et al., the theme is varied based on the amplitude dimension. It means the setup pertaining to time dimension in Bhandari et al. is same as standard Nyquist sampling set up. This standard setup requires that the signal is smooth in canonical (time/space) basis, and considers uniform grid for sampling. However, the measurement set up along amplitude dimension is modulo. To recover the signal from the modulo measurements perfectly, the sampling frequency has to be greater than $2e(bandwidth)$.}
\textcolor{red}{
Now, just as Nyquist Shannon sampling and Compressive Sampling is complimentary to each other, ours and Bhandari et al.'s approach seems to be complimentary. Maybe it can be put in this form: In Bhandari et al., the theme is varied only along the amplitude dimension, while in our case, we vary from the standard Nyquist sampling along both the time and amplitude dimension, as we consider both the modulo sampling and sparsity. Also, the method of modulo recovery proposed in Bhandari et al. rely on smoothness, thus cannot be applied in our sparsity based setup.
}

\textcolor{red}{ About comparision between Tyagi et al. and Our approach:: \\
The main focus of the work of Tyagi et al. is not the modulo recovery, but the denoising of modulo measurements. However, in the later part of their paper, to complete the entire process, they do provide two different algorithms for modulo recovery once the modulo observations are denoised. Again, the basis of the Tyagi et al. is same as Bhandari at al,  as they also consider a variation along amplitude dimension only (bandlimited signal, smoothness etc. ).Their modulo recovery algorithm rely on smoothness of the function. They do not provide sample complexity bounds as their main focus is on the denoising part. Also, similar to Bhandari et al., the method of modulo recovery proposed in Tyagi et al. rely on smoothness, thus cannot be applied in our sparsity based setup.}

\textcolor{red}{About comparision between Single Shot UHDR, Zhao and Rasker et al.  and Our approach::\\
	Again, here also the setup is standard Nyquist Shannon, in spatial basis. The key assumption is smoothness of the 'image' in the spatial domain. No sample complexity bounds are provided. similar to Bhandari et al., the method of modulo recovery proposed here also rely on smoothness (in spatial domain, instead of time domain), thus cannot be applied in our sparsity based setup.}

\textcolor{red}{ About comparision between Multi-Shot UHDR, Zhao and Rasker et al.  and Our approach::\\
	Here, the measurements are taken in spatial domain, but there is no assumption of smoothness. Here the sampling is non-uniform grid (because of the presence of the carefully chosen multipliers implemented through exposure times). In a way it is similar to our setup of non-uniform sampling, but the sparsity  (or any other signal structure) is not leveraged. Thus, the practical sample complexity is very high ( $m$ is at least 2 times the value of $n$). No theoretical analysis provided. This method is compatible to be used with sparsity (as we have used it in our asilomar paper), but the oversampling factor and difficulty in choosing the multipliers are the drawbacks here.}